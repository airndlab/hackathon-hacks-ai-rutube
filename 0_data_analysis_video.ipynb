{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e52c6de5-67b6-4f46-837c-6735f17dfa66",
   "metadata": {},
   "source": [
    "# Исходные данные\n",
    "## Структура датасета метаданных видео videos.parquet + features.parquet\n",
    "\n",
    "| Поле | Описание |\n",
    "|------|----------|\n",
    "| video_id | Идентификатор видео |\n",
    "| video_title | Название видео |\n",
    "| channel_title | Название канала |\n",
    "| v_channel_reg_datetime | Дата регистрации канала |\n",
    "| v_channel_type | Тип канала |\n",
    "| v_category | Категория видео |\n",
    "| v_pub_datetime | Дата публикации видео |\n",
    "| report_date | Дата на момент которой собирались данные признаки |\n",
    "| total_comments | Количество комментариев под видео |\n",
    "| v_year_views | Количество просмотров за год |\n",
    "| v_month_views | Количество просмотров за месяц |\n",
    "| v_week_views | Количество просмотров за неделю |\n",
    "| v_day_views | Количество просмотров за день |\n",
    "| v_likes | Количество лайков |\n",
    "| v_dislikes | Количество дизлайков |\n",
    "| v_duration | Продолжительность видео в миллисекундах |\n",
    "| v_cr_click_like_7_days | Конверсия клика в лайк за 7 дней |\n",
    "| v_cr_click_dislike_7_days | Конверсия клика в дизлайк за 7 дней |\n",
    "| v_cr_click_vtop_7_days | Конверсия клика в нажатие \"в топ\" за 7 дней |\n",
    "| v_cr_click_long_view_7_days | Конверсия клика в долгий просмотр за 7 дней |\n",
    "| v_cr_click_comment_7_days | Конверсия клика в комментарий за 7 дней |\n",
    "| v_cr_click_like_30_days | Конверсия клика в лайк за 30 дней |\n",
    "| v_cr_click_dislike_30_days | Конверсия клика в дизлайк за 30 дней |\n",
    "| v_cr_click_vtop_30_days | Конверсия клика в нажатие \"в топ\" за 30 дней |\n",
    "| v_cr_click_long_view_30_days | Конверсия клика в долгий просмотр за 30 дней |\n",
    "| v_cr_click_comment_30_days | Конверсия клика в комментарий за 30 дней |\n",
    "| v_cr_click_like_1_days | Конверсия клика в лайк за 1 день |\n",
    "| v_cr_click_dislike_1_days | Конверсия клика в дизлайк за 1 день |\n",
    "| v_cr_click_vtop_1_days | Конверсия клика в нажатие \"в топ\" за 1 день |\n",
    "| v_cr_click_long_view_1_days | Конверсия клика в долгий просмотр за 1 день |\n",
    "| v_cr_click_comment_1_days | Конверсия клика в комментарий за 1 день |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e035693-e523-4cf1-a54d-b76b922c5803",
   "metadata": {},
   "source": [
    "# Вопросы\n",
    "\n",
    "- Какие топ видео и каналы? Что смотрят в массе?\n",
    "- Какая динамика? Что смотрят больше?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba21a66-d1a0-4340-baf9-12d232efea98",
   "metadata": {},
   "source": [
    "# Анализ данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034dc41c-551c-4072-9523-10c848241220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import nltk \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('popular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68a23d2-88ec-4d60-8a8f-0e1827f4483c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('popular')\n",
    "\n",
    "# Загрузка датасета\n",
    "df = pd.read_parquet('rutube_case/automarkup_10k.parquet')\n",
    "\n",
    "# Очистка текста (пример функции)\n",
    "def clean_text(text):\n",
    "    # Удаление специальных символов и приведение к нижнему регистру\n",
    "    text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "    # Токенизация\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # Удаление стоп-слов\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('russian')]\n",
    "    # Лемматизация\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Применение функции очистки текста к столбцу с запросами\n",
    "df['cleaned_query'] = df['query'].apply(clean_text)\n",
    "\n",
    "# Анализ частоты слов с использованием CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df['cleaned_query'])\n",
    "\n",
    "# Получение суммарной частоты слов\n",
    "word_freq = dict(zip(vectorizer.get_feature_names_out(), X.toarray().sum(axis=0)))\n",
    "\n",
    "# Визуализация наиболее популярных слов с помощью Word Cloud\n",
    "wordcloud = WordCloud(width=800, height=400, background_color ='white').generate_from_frequencies(word_freq)\n",
    "\n",
    "# Отображение Word Cloud\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044e121c-a960-4bb8-8d69-f34ab3e1e9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Загрузка датасета\n",
    "df = pd.read_parquet('rutube_case/automarkup.parquet')\n",
    "\n",
    "# Нахождение самых частых запросов\n",
    "query_counts = Counter(df['query'])\n",
    "most_common_queries = query_counts.most_common(10)  # Топ-10 запросов\n",
    "\n",
    "# Получение количества видео по самым частым запросам\n",
    "video_count_by_query = df[df['query'].isin([q[0] for q in most_common_queries])].groupby('query')['video_id'].nunique()\n",
    "\n",
    "# Нахождение видео, которые чаще всего запрашивают\n",
    "most_requested_videos = df['video_id'].value_counts().head(10)  # Топ-10 запрашиваемых видео\n",
    "\n",
    "# Распределение по авторизованности пользователей\n",
    "auth_query_distribution = df.groupby('is_authorized')['query'].count()\n",
    "\n",
    "# Анализ длины запросов\n",
    "query_length = df['query'].apply(len)\n",
    "query_length_stats = {\n",
    "    'average_length': query_length.mean(),\n",
    "    'max_length': query_length.max(),\n",
    "    'min_length': query_length.min(),\n",
    "}\n",
    "\n",
    "# Классификация запросов и количество по категориям (примерная реализация)\n",
    "# Для реальной классификации нужен более сложный подход, возможно с использованием машинного обучения\n",
    "query_category = {\n",
    "    'query': 'category'\n",
    "    # Заполните категории в зависимости от запросов и предполагаемых категорий\n",
    "}\n",
    "df['category'] = df['query'].map(query_category)  # Маппинг запросов на категории\n",
    "category_counts = df['category'].value_counts()\n",
    "\n",
    "# Вывод результатов\n",
    "print(\"Самые частые запросы:\\n\", most_common_queries)\n",
    "print(\"\\nКоличество уникальных видео по запросам:\\n\", video_count_by_query)\n",
    "print(\"\\nНаиболее часто запрашиваемые видео:\\n\", most_requested_videos)\n",
    "print(\"\\nРаспределение запросов по авторизованности пользователей:\\n\", auth_query_distribution)\n",
    "print(\"\\nСтатистика по длине запросов:\\n\", query_length_stats)\n",
    "print(\"\\nКоличество запросов по категориям:\\n\", category_counts)\n",
    "\n",
    "# Визуализация данных (можно добавить графики, если это необходимо)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac617ad-8acd-40af-933a-c15b51bf4ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Загрузка стоп-слов, для русского языка используйте 'russian'\n",
    "stop_words = set(stopwords.words('russian'))\n",
    "\n",
    "# Функция для очистки текста\n",
    "def clean_text(text: pl.Series) -> pl.Series:\n",
    "    # Удаление знаков препинания и цифр, приведение к нижнему регистру\n",
    "    text = text.str.replace(r'[^\\w\\s]', '', regex=True).str.replace(r'\\d+', '', regex=True).str.to_lowercase()    \n",
    "    # Удаление стоп-слов\n",
    "    text = text.apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "    return text\n",
    "\n",
    "# Функция для очистки текста\n",
    "def clean_text_pl(text: str) -> str:\n",
    "    # Удаление знаков препинания и цифр, приведение к нижнему регистру\n",
    "    text = re.sub(r'[^\\w\\s]', '', text).lower()\n",
    "    # Удаление стоп-слов\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "# Функция для очистки текстовых столбцов в DataFrame\n",
    "def clean_text_column(col: pl.Series) -> pl.Series:\n",
    "    return col.map_elements(clean_text_pl)\n",
    "\n",
    "# Загрузка датасетов\n",
    "markup_df = pl.read_parquet('rutube_case/automarkup.parquet')\n",
    "videos_df = pl.read_parquet('rutube_case/videos.parquet')\n",
    "features_df = pl.read_parquet('rutube_case/features.parquet')\n",
    "\n",
    "head_cnt = 30\n",
    "\n",
    "# Соединение датасетов по полю video_id\n",
    "merged_df = markup_df.join(videos_df, how='inner', on='video_id', )\n",
    "\n",
    "merged_df = merged_df.with_columns([\n",
    "    clean_text_column(pl.col('query')).alias('query_cleaned'),\n",
    "    clean_text_column(pl.col('video_title')).alias('video_title_cleaned'),\n",
    "    clean_text_column(pl.col('channel_title')).alias('channel_title_cleaned')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09c04bd-8f69-455e-9e39-bafb1432692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Количество каналов\n",
    "channel_count = merged_df.select('channel_title').unique().count()\n",
    "\n",
    "# Количество видео по каналам\n",
    "video_count_by_channel = merged_df.groupby('channel_title').agg(pl.count('video_id').alias('video_count')).sort('video_count', reverse=True).head(head_cnt)\n",
    "\n",
    "# Количество видео по категориям\n",
    "video_count_by_category = merged_df.groupby('v_category').agg(pl.count('video_id').alias('video_count')).sort('video_count', reverse=True).head(head_cnt)\n",
    "\n",
    "# Количество видео по реакциям пользователей\n",
    "video_reaction_stats = merged_df.select(['v_likes', 'v_dislikes', 'total_comments']).sum()\n",
    "\n",
    "# Визуализация количества видео по каналам\n",
    "video_count_by_channel.to_pandas().set_index('channel_title')['video_count'].plot(kind='bar', title='Количество видео по каналам')\n",
    "plt.show()\n",
    "\n",
    "# Визуализация количества видео по категориям\n",
    "video_count_by_category.to_pandas().set_index('v_category')['video_count'].plot(kind='bar', title='Количество видео по категориям')\n",
    "plt.show()\n",
    "\n",
    "# Визуализация количества видео по реакциям пользователей\n",
    "video_reaction_stats.to_frame().plot(kind='bar', title='Реакции пользователей на видео')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05659346-08e8-4908-92e4-242c91b0dbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "df = pl.read_parquet('rutube_case/automarkup.parquet')\n",
    "subset_df = df.head(10000)\n",
    "subset_df.write_parquet('rutube_case/automarkup_10k.parquet')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
